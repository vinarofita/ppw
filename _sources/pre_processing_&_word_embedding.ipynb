{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Pre-processing & word embedding"
      ],
      "metadata": {
        "id": "QEdDyG_vxt4j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Load data dari g-drive\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ku0SRwVsEwXW",
        "outputId": "dfe0c6e1-a7d5-4919-914a-db5db2b3e0c2"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kVj93sctEmyk",
        "outputId": "6926ed3a-8e61-420f-ea28-1700a7032145"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                               judul  \\\n",
            "0                                    Title Not Found   \n",
            "1  Mensos Ajak Kepala Daerah Kolaborasi Sukseskan...   \n",
            "2  Mendagri & CIO Danantara Bahas Penguatan Pendi...   \n",
            "3  Video: Alasan Tersangka Penculikan Kacab Bank ...   \n",
            "4  Kemnaker Catat 16.900 Pengunjung PTSA, Mayorit...   \n",
            "\n",
            "                                                 isi kategori  \n",
            "0                                  Content Not Found  Politik  \n",
            "1  Jakarta - Menteri Sosial Saifullah Yusuf (Gus ...  Politik  \n",
            "2  Jakarta - Menteri Dalam Negeri Muhammad Tito K...  Politik  \n",
            "3  Polisi mengungkap alasan para tersangka pencul...  Politik  \n",
            "4  Jakarta - Kementerian Ketenagakerjaan (Kemnake...  Politik  \n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('/content/drive/MyDrive/semester 5/ppw/CrawlBerita_Politik-Olahraga.csv')\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Cleaning text"
      ],
      "metadata": {
        "id": "kGvovLEOFDSv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dataset\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/semester 5/ppw/CrawlBerita_Politik-Olahraga.csv\")  # ganti dengan nama file kamu\n",
        "\n",
        "# Ambil kolom abstrak\n",
        "df = df[[ 'isi','kategori']]\n",
        "print(df.head)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KbsHLjkuFZOd",
        "outputId": "7541a7e6-92e6-4072-efcf-e8e4053f2869"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<bound method NDFrame.head of                                                    isi  kategori\n",
            "0                                    Content Not Found   Politik\n",
            "1    Jakarta - Menteri Sosial Saifullah Yusuf (Gus ...   Politik\n",
            "2    Jakarta - Menteri Dalam Negeri Muhammad Tito K...   Politik\n",
            "3    Polisi mengungkap alasan para tersangka pencul...   Politik\n",
            "4    Jakarta - Kementerian Ketenagakerjaan (Kemnake...   Politik\n",
            "..                                                 ...       ...\n",
            "195  Jakarta - Pasangan ganda putri Indonesia Febri...  Olahraga\n",
            "196  Daftar Isi Jadwal dan hasil wakil Indonesia di...  Olahraga\n",
            "197  Hong Kong - Delapan wakil Indonesia bertanding...  Olahraga\n",
            "198  Jakarta - Timnas Wushu Indonesia sudah menunta...  Olahraga\n",
            "199  Jakarta - Seri Kejuaraan Dunia Teqball atau Wo...  Olahraga\n",
            "\n",
            "[200 rows x 2 columns]>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "# ===== Load dataset =====\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/semester 5/ppw/CrawlBerita_Politik-Olahraga.csv\")  # ganti sesuai path\n",
        "\n",
        "# ===== Ambil kolom 'isi' dan 'kategori' =====\n",
        "df = df[['isi', 'kategori']]\n",
        "\n",
        "# ===== Fungsi untuk text cleaning =====\n",
        "def clean_text(text):\n",
        "    text = str(text).lower()                  # lowercase\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)       # hapus tanda baca\n",
        "    text = re.sub(r'\\s+', ' ', text).strip() # hapus spasi ekstra\n",
        "    return text\n",
        "\n",
        "# ===== Terapkan pembersihan dan simpan di kolom baru 'isi_clean' =====\n",
        "df['isi_clean'] = df['isi'].apply(clean_text)\n",
        "\n",
        "# ===== Cek hasil =====\n",
        "print(df[['isi', 'isi_clean', 'kategori']].head())\n",
        "print(df.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Xiz38QYGgzr",
        "outputId": "914f3227-0107-473a-954a-f5aab49173e0"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                 isi  \\\n",
            "0                                  Content Not Found   \n",
            "1  Jakarta - Menteri Sosial Saifullah Yusuf (Gus ...   \n",
            "2  Jakarta - Menteri Dalam Negeri Muhammad Tito K...   \n",
            "3  Polisi mengungkap alasan para tersangka pencul...   \n",
            "4  Jakarta - Kementerian Ketenagakerjaan (Kemnake...   \n",
            "\n",
            "                                           isi_clean kategori  \n",
            "0                                  content not found  Politik  \n",
            "1  jakarta menteri sosial saifullah yusuf gus ipu...  Politik  \n",
            "2  jakarta menteri dalam negeri muhammad tito kar...  Politik  \n",
            "3  polisi mengungkap alasan para tersangka pencul...  Politik  \n",
            "4  jakarta kementerian ketenagakerjaan kemnaker m...  Politik  \n",
            "(200, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cek ejaan kata"
      ],
      "metadata": {
        "id": "EmUjM1UPQMaV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Kamus kata tidak baku → kata baku\n",
        "kamus_kata = {\n",
        "    \"tehnik\": \"teknik\",\n",
        "    \"yg\": \"yang\",\n",
        "    \"tdk\": \"tidak\",\n",
        "    \"dr\": \"dari\",\n",
        "    \"utk\": \"untuk\",\n",
        "    \"dlm\": \"dalam\",\n",
        "    \"tp\": \"tapi\",\n",
        "    \"jg\": \"juga\",\n",
        "    \"krn\": \"karena\",\n",
        "    \"bkn\": \"bukan\",\n",
        "    \"sdh\": \"sudah\",\n",
        "    \"sm\": \"sama\"\n",
        "}\n",
        "\n",
        "def normalisasi_kata(teks):\n",
        "    kata = teks.split()\n",
        "    kata_baru = []\n",
        "    for k in kata:\n",
        "        # jika ada di kamus_kata → ganti\n",
        "        kata_baru.append(kamus_kata.get(k, k))\n",
        "    return \" \".join(kata_baru)\n",
        "\n",
        "# Terapkan normalisasi\n",
        "df['isi(cek ejaan)'] = df['isi_clean'].astype(str).apply(normalisasi_kata)\n",
        "\n",
        "print(df[['isi','isi_clean', 'isi(cek ejaan)']].head())"
      ],
      "metadata": {
        "id": "ZBKJxG6LQH15",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0475181a-7541-4f52-936e-a06f8e6e0cfc"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                 isi  \\\n",
            "0                                  Content Not Found   \n",
            "1  Jakarta - Menteri Sosial Saifullah Yusuf (Gus ...   \n",
            "2  Jakarta - Menteri Dalam Negeri Muhammad Tito K...   \n",
            "3  Polisi mengungkap alasan para tersangka pencul...   \n",
            "4  Jakarta - Kementerian Ketenagakerjaan (Kemnake...   \n",
            "\n",
            "                                           isi_clean  \\\n",
            "0                                  content not found   \n",
            "1  jakarta menteri sosial saifullah yusuf gus ipu...   \n",
            "2  jakarta menteri dalam negeri muhammad tito kar...   \n",
            "3  polisi mengungkap alasan para tersangka pencul...   \n",
            "4  jakarta kementerian ketenagakerjaan kemnaker m...   \n",
            "\n",
            "                                      isi(cek ejaan)  \n",
            "0                                  content not found  \n",
            "1  jakarta menteri sosial saifullah yusuf gus ipu...  \n",
            "2  jakarta menteri dalam negeri muhammad tito kar...  \n",
            "3  polisi mengungkap alasan para tersangka pencul...  \n",
            "4  jakarta kementerian ketenagakerjaan kemnaker m...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenisasi(teks):\n",
        "    # Pisah berdasarkan spasi & hilangkan token kosong\n",
        "    tokens = re.findall(r'\\b\\w+\\b', str(teks))\n",
        "    return tokens\n",
        "\n",
        "# Terapkan tokenisasi\n",
        "df['isi_tokens'] = df['isi_clean'].apply(tokenisasi)\n",
        "# Contoh hasil\n",
        "print(df[['isi','isi_tokens','kategori']].head())\n",
        "\n",
        "# Simpan hasil\n",
        "df.to_csv(\"hasil-pre-pro_isi_berita.csv\", index=False, encoding=\"utf-8-sig\")\n",
        "print(\"✅ Hasil disimpan di hasil-pre-pro_isi_berita.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3naDmlHUNnXn",
        "outputId": "2ad097a5-ceee-49b0-cf45-cdefb83c6712"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                 isi  \\\n",
            "0                                  Content Not Found   \n",
            "1  Jakarta - Menteri Sosial Saifullah Yusuf (Gus ...   \n",
            "2  Jakarta - Menteri Dalam Negeri Muhammad Tito K...   \n",
            "3  Polisi mengungkap alasan para tersangka pencul...   \n",
            "4  Jakarta - Kementerian Ketenagakerjaan (Kemnake...   \n",
            "\n",
            "                                          isi_tokens kategori  \n",
            "0                              [content, not, found]  Politik  \n",
            "1  [jakarta, menteri, sosial, saifullah, yusuf, g...  Politik  \n",
            "2  [jakarta, menteri, dalam, negeri, muhammad, ti...  Politik  \n",
            "3  [polisi, mengungkap, alasan, para, tersangka, ...  Politik  \n",
            "4  [jakarta, kementerian, ketenagakerjaan, kemnak...  Politik  \n",
            "✅ Hasil disimpan di hasil-pre-pro_isi_berita.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gensim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JbGbEBSbHTY0",
        "outputId": "029c4434-dda9-4d99-d1c1-98b4f4a7d2f5"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.12/dist-packages (4.3.3)\n",
            "Requirement already satisfied: numpy<2.0,>=1.18.5 in /usr/local/lib/python3.12/dist-packages (from gensim) (1.26.4)\n",
            "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from gensim) (1.13.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.12/dist-packages (from gensim) (7.3.1)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart-open>=1.8.1->gensim) (1.17.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from gensim.models import Word2Vec\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "import re\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv(\"/content/hasil-pre-pro_isi_berita.csv\")  # ganti sesuai path\n",
        "\n",
        "# Ambil kolom 'isi' dan 'kategori'\n",
        "df = df[['isi', 'kategori']]\n",
        "\n",
        "# Fungsi untuk text cleaning\n",
        "def clean_text(text):\n",
        "    text = str(text).lower()                  # lowercase\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)       # hapus tanda baca\n",
        "    text = re.sub(r'\\s+', ' ', text).strip() # hapus spasi ekstra\n",
        "    return text\n",
        "\n",
        "# Terapkan pembersihan dan simpan di kolom baru 'isi_clean'\n",
        "df['isi_clean'] = df['isi'].apply(clean_text)\n",
        "\n",
        "# Tokenisasi\n",
        "def tokenisasi(teks):\n",
        "    # Pisah berdasarkan spasi & hilangkan token kosong\n",
        "    tokens = re.findall(r'\\b\\w+\\b', str(teks))\n",
        "    return tokens\n",
        "\n",
        "# Terapkan tokenisasi\n",
        "df['isi_tokens'] = df['isi_clean'].apply(tokenisasi)\n",
        "\n",
        "\n",
        "# ===== Latih Word2Vec =====\n",
        "w2v_model = Word2Vec(\n",
        "    sentences=df['isi_tokens'],\n",
        "    vector_size=100,   # jumlah dimensi vektor\n",
        "    window=5,\n",
        "    min_count=1,\n",
        "    workers=4\n",
        ")\n",
        "\n",
        "# ===== Buat embedding per dokumen =====\n",
        "def doc_vector(tokens, model):\n",
        "    vectors = [model.wv[t] for t in tokens if t in model.wv]\n",
        "    if len(vectors) == 0:\n",
        "        return np.zeros(model.vector_size)\n",
        "    else:\n",
        "        return np.mean(vectors, axis=0)\n",
        "\n",
        "X = np.array([doc_vector(tokens, w2v_model) for tokens in df['isi_tokens']])\n",
        "y = df['kategori']  # label kategori\n",
        "\n",
        "# ===== Split data latih & uji =====\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# ===== Latih Naive Bayes =====\n",
        "nb_model = GaussianNB()\n",
        "nb_model.fit(X_train, y_train)\n",
        "\n",
        "# ===== Prediksi & evaluasi =====\n",
        "y_pred = nb_model.predict(X_test)\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tjF6IzkiHOzl",
        "outputId": "7d293c3a-bcab-495c-ac5e-c192b5c8e563"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.65\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    Olahraga       0.80      0.40      0.53        20\n",
            "     Politik       0.60      0.90      0.72        20\n",
            "\n",
            "    accuracy                           0.65        40\n",
            "   macro avg       0.70      0.65      0.63        40\n",
            "weighted avg       0.70      0.65      0.63        40\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from gensim.models import Word2Vec\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# ==============================\n",
        "# 1. Word2Vec + Naive Bayes\n",
        "# ==============================\n",
        "# Latih Word2Vec\n",
        "w2v_model = Word2Vec(\n",
        "    sentences=df['isi_tokens'],\n",
        "    vector_size=50,\n",
        "    window=5,\n",
        "    min_count=1,\n",
        "    workers=1\n",
        ")\n",
        "\n",
        "# Fungsi buat dokumen embedding\n",
        "def doc_vector(tokens, model):\n",
        "    vectors = [model.wv[t] for t in tokens if t in model.wv]\n",
        "    return np.mean(vectors, axis=0) if len(vectors) > 0 else np.zeros(model.vector_size)\n",
        "\n",
        "X_w2v = np.array([doc_vector(tokens, w2v_model) for tokens in df['isi_tokens']])\n",
        "y = df['kategori']\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_w2v, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# Latih Naive Bayes (Gaussian untuk data numerik continuous)\n",
        "nb_w2v = GaussianNB()\n",
        "nb_w2v.fit(X_train, y_train)\n",
        "\n",
        "# Prediksi\n",
        "y_pred_w2v = nb_w2v.predict(X_test)\n",
        "\n",
        "print(\"=== Word2Vec + Naive Bayes ===\")\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred_w2v))\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_w2v))\n",
        "\n",
        "\n",
        "# ==============================\n",
        "# 2. TF-IDF + Naive Bayes\n",
        "# ==============================\n",
        "# Gabungkan tokens jadi string agar bisa diproses TF-IDF\n",
        "df['isi_join'] = df['isi_tokens'].apply(lambda x: \" \".join(x))\n",
        "\n",
        "# Buat TF-IDF vektorizer\n",
        "tfidf = TfidfVectorizer(max_features=5000)  # bisa dibatasi max fitur\n",
        "X_tfidf = tfidf.fit_transform(df['isi_join'])\n",
        "\n",
        "# Split data\n",
        "X_train_tfidf, X_test_tfidf, y_train, y_test = train_test_split(\n",
        "    X_tfidf, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# Latih Naive Bayes (Multinomial untuk data frekuensi/TF-IDF)\n",
        "nb_tfidf = MultinomialNB()\n",
        "nb_tfidf.fit(X_train_tfidf, y_train)\n",
        "\n",
        "# Prediksi\n",
        "y_pred_tfidf = nb_tfidf.predict(X_test_tfidf)\n",
        "\n",
        "print(\"\\n=== TF-IDF + Naive Bayes ===\")\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred_tfidf))\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_tfidf))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rda4YYdsPfMH",
        "outputId": "5b38d53f-e9fb-4ecf-c0a1-9d51fd463ef4"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Word2Vec + Naive Bayes ===\n",
            "Accuracy: 0.675\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    Olahraga       0.82      0.45      0.58        20\n",
            "     Politik       0.62      0.90      0.73        20\n",
            "\n",
            "    accuracy                           0.68        40\n",
            "   macro avg       0.72      0.68      0.66        40\n",
            "weighted avg       0.72      0.68      0.66        40\n",
            "\n",
            "\n",
            "=== TF-IDF + Naive Bayes ===\n",
            "Accuracy: 0.95\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    Olahraga       1.00      0.90      0.95        20\n",
            "     Politik       0.91      1.00      0.95        20\n",
            "\n",
            "    accuracy                           0.95        40\n",
            "   macro avg       0.95      0.95      0.95        40\n",
            "weighted avg       0.95      0.95      0.95        40\n",
            "\n"
          ]
        }
      ]
    }
  ]
}